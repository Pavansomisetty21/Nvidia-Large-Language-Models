{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# classification"
      ],
      "metadata": {
        "id": "eqNYyHs1za-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ9MIzeiyRWR",
        "outputId": "39c6c3f0-e9a1-4807-f70d-f74b52984f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found google/gemma-3-1b-it in available_models, but type is unknown and inference may fail.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's a classification of the text \"You are beautiful\" – it’s a simple, straightforward sentiment expressed. Here's a breakdown:\n",
            "\n",
            "**Category:**\n",
            "\n",
            "*   **Positive Sentiment:** This is the primary classification. The text expresses a feeling of admiration and appreciation.\n",
            "*   **Compliment:** It's a direct compliment, expressing a positive assessment of the recipient.\n",
            "*   **Expressive:** It's a short, concise way to convey a feeling.\n",
            "\n",
            "**More Detailed Breakdown:**\n",
            "\n",
            "*   **Type:**  Simple, declarative statement.\n",
            "*   **Emotional Tone:**  Warm, affectionate, and appreciative.\n",
            "*   **Purpose:** To express positive feelings and potentially elicit a positive response.\n",
            "\n",
            "**In short, it's a lovely, uplifting message!**\n",
            "\n",
            "Do you want me to classify it further, perhaps by:\n",
            "\n",
            "*   **Context:** (e.g., a social media post, a romantic message, etc.)\n",
            "*   **Genre:** (e.g., poetry, advertising, etc.)"
          ]
        }
      ],
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "client = ChatNVIDIA(\n",
        "  model=\"google/gemma-3-1b-it\",\n",
        "  api_key=\"nvapikey\",\n",
        "  temperature=0.1,\n",
        "  top_p=0.7,\n",
        "  max_tokens=512,\n",
        ")\n",
        "\n",
        "test=\"you are beautiful\"\n",
        "for chunk in client.stream([{\"role\":\"user\",\"content\":f\"classify the text{test}\"}]):\n",
        "  print(chunk.content, end=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER"
      ],
      "metadata": {
        "id": "rEDEAFoqzm7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "client = ChatNVIDIA(\n",
        "  model=\"google/gemma-3-1b-it\",\n",
        "  api_key=\"nvapikey\",\n",
        "  temperature=0.1,\n",
        "  top_p=0.7,\n",
        "  max_tokens=512,\n",
        ")\n",
        "\n",
        "test=\"you are beautiful\"\n",
        "for chunk in client.stream([{\"role\":\"user\",\"content\":f\"give named entities the text{test}\"}]):\n",
        "  print(chunk.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltP33ARjybU-",
        "outputId": "932a19ab-ccdd-4788-9ccb-2f1533befb0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found google/gemma-3-1b-it in available_models, but type is unknown and inference may fail.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's a breakdown of the named entities in the text \"You are beautiful\":\n",
            "\n",
            "*   **You:** Person\n",
            "*   **beautiful:** Noun\n",
            "\n",
            "Let me know if you'd like me to analyze a different text!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation"
      ],
      "metadata": {
        "id": "pkKDvbq9BY0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "client = ChatNVIDIA(\n",
        "  model=\"google/gemma-3-1b-it\",\n",
        "  api_key=\"nvapikey\",\n",
        "  temperature=0.1,\n",
        "  top_p=0.7,\n",
        "  max_tokens=512,\n",
        ")\n",
        "test=\"you are beautiful\"\n",
        "for chunk in client.stream([{\"role\":\"user\",\"content\":f\"what is  llms?\"}]):\n",
        "  print(chunk.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSfp3fl2zHDt",
        "outputId": "9e245a37-123b-41ae-fd87-c2fde1757946"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_nvidia_ai_endpoints/_common.py:212: UserWarning: Found google/gemma-3-1b-it in available_models, but type is unknown and inference may fail.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's break down what LLMs are – Large Language Models. Here's a comprehensive explanation:\n",
            "\n",
            "**What are LLMs?**\n",
            "\n",
            "LLMs (Large Language Models) are a type of artificial intelligence (AI) that are trained on massive amounts of text data. They're designed to understand, generate, and manipulate human language. Think of them as incredibly sophisticated predictive text engines, but with a much broader range of capabilities.\n",
            "\n",
            "**Here's a breakdown of key aspects:**\n",
            "\n",
            "* **\"Large\"**: The \"large\" in LLM refers to the sheer size of the model – both in terms of the amount of data it's trained on and the number of parameters (the adjustable values within the model).\n",
            "* **\"Language\"**: LLMs are specifically focused on language – text, code, and even some audio.\n",
            "* **\"Model\"**:  It's a statistical model.  They learn patterns and relationships within the data they're trained on.  They don't \"understand\" language in the same way a human does; they predict the *most likely* next word or sequence of words based on what they've seen.\n",
            "\n",
            "**How do they work?**\n",
            "\n",
            "1. **Training:** LLMs are trained using techniques like:\n",
            "   * **Self-Supervised Learning:** They're fed huge datasets of text (books, articles, websites, code, etc.) and learn to predict the next word in a sequence.  For example, they might be given the sentence \"The cat sat on the...\" and asked to predict \"mat.\"\n",
            "   * **Transformer Architecture:** Most modern LLMs are based on a neural network architecture called the \"Transformer.\" This architecture is particularly good at handling long-range dependencies in text – meaning it can understand how words relate to each other even if they're far apart in a sentence or paragraph.\n",
            "\n",
            "2. **Parameters:**  The \"size\" of an LLM is measured by the number of parameters it has.  More parameters generally mean a more complex model that can learn more intricate patterns.  Examples include:\n",
            "   * **GPT-3:**  Has 175 billion parameters.\n",
            "   * **LLaMA 2:** Has 7 billion parameters.\n",
            "\n",
            "3. **Inference (Using the Model):** Once trained, you can give an LLM a prompt (a question, a statement, or a starting text) and it will generate a response.  It predicts"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzPO30guzP_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
